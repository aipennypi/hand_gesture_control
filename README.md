Hand Gesture Control for Keyboard Simulation for game control
This project uses computer vision and machine learning techniques to detect hand gestures and map them to keyboard commands. The application utilizes MediaPipe for hand tracking and PyAutoGUI for simulating keyboard inputs, enabling intuitive gesture-based interaction.

Features
Gesture Detection:

Detects hand movements and finger positions using MediaPipe's hand tracking model.
Identifies specific gestures like moving fingers up, down, left, or right.
Keyboard Control:

Maps detected gestures to keyboard commands:
Up Gesture: Simulates pressing the "Up Arrow" key.
Down Gesture: Simulates pressing the "Down Arrow" key.
Left Gesture: Simulates pressing the "Left Arrow" key (Clockwise Rotation).
Right Gesture: Simulates pressing the "Right Arrow" key (Counterclockwise Rotation).
Real-Time Feedback:

Displays detected gestures on the screen with corresponding text annotations.

We can use this feature to control keyboard when you play the PC game.
